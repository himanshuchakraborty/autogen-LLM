{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautogen\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AssistantAgent, UserProxyAgent, config_list_from_json\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load LLM inference endpoints from an env variable or a file\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# See https://microsoft.github.io/autogen/docs/FAQ#set-your-api-endpoints\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# and OAI_CONFIG_LIST_sample.json\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m config_list \u001b[38;5;241m=\u001b[39m \u001b[43mconfig_list_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_or_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOAI_CONFIG_LIST.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m assistant \u001b[38;5;241m=\u001b[39m AssistantAgent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, llm_config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig_list\u001b[39m\u001b[38;5;124m\"\u001b[39m: config_list})\n\u001b[0;32m      8\u001b[0m user_proxy \u001b[38;5;241m=\u001b[39m UserProxyAgent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_proxy\u001b[39m\u001b[38;5;124m\"\u001b[39m, code_execution_config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwork_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_docker\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}) \u001b[38;5;66;03m# IMPORTANT: set to True to run code in docker, recommended\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hchakra1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autogen\\oai\\openai_utils.py:487\u001b[0m, in \u001b[0;36mconfig_list_from_json\u001b[1;34m(env_or_file, file_location, filter_dict)\u001b[0m\n\u001b[0;32m    485\u001b[0m     config_list_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(file_location, env_or_file)\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(config_list_path) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[1;32m--> 487\u001b[0m         config_list \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filter_config(config_list, filter_dict)\n",
      "File \u001b[1;32mc:\\Users\\hchakra1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hchakra1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\hchakra1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\hchakra1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent, config_list_from_json\n",
    "\n",
    "# Load LLM inference endpoints from an env variable or a file\n",
    "# See https://microsoft.github.io/autogen/docs/FAQ#set-your-api-endpoints\n",
    "# and OAI_CONFIG_LIST_sample.json\n",
    "config_list = config_list_from_json(env_or_file=\"OAI_CONFIG_LIST.txt\")\n",
    "assistant = AssistantAgent(\"assistant\", llm_config={\"config_list\": config_list})\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", code_execution_config={\"work_dir\": \"coding\", \"use_docker\": False}) # IMPORTANT: set to True to run code in docker, recommended\n",
    "user_proxy.initiate_chat(assistant, message=\"Plot a chart of NVDA and TESLA stock price change YTD.\")\n",
    "# This initiates an automated chat between the two agents to solve the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyautogen\n",
      "  Downloading pyautogen-0.2.8-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting diskcache (from pyautogen)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting docker (from pyautogen)\n",
      "  Downloading docker-7.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting flaml (from pyautogen)\n",
      "  Downloading FLAML-2.1.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting openai>=1.3 (from pyautogen)\n",
      "  Downloading openai-1.9.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting pydantic<3,>=1.10 (from pyautogen)\n",
      "  Using cached pydantic-2.5.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting python-dotenv (from pyautogen)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting termcolor (from pyautogen)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting tiktoken (from pyautogen)\n",
      "  Downloading tiktoken-0.5.2-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai>=1.3->pyautogen)\n",
      "  Downloading anyio-4.2.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.3->pyautogen)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai>=1.3->pyautogen)\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting sniffio (from openai>=1.3->pyautogen)\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting tqdm>4 (from openai>=1.3->pyautogen)\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.7 (from openai>=1.3->pyautogen)\n",
      "  Using cached typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.10->pyautogen)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.6 (from pydantic<3,>=1.10->pyautogen)\n",
      "  Downloading pydantic_core-2.14.6-cp312-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: packaging>=14.0 in c:\\users\\hchakra1\\appdata\\roaming\\python\\python312\\site-packages (from docker->pyautogen) (23.2)\n",
      "Collecting requests>=2.26.0 (from docker->pyautogen)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting urllib3>=1.26.0 (from docker->pyautogen)\n",
      "  Downloading urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\hchakra1\\appdata\\roaming\\python\\python312\\site-packages (from docker->pyautogen) (306)\n",
      "Collecting NumPy>=1.17.0rc1 (from flaml->pyautogen)\n",
      "  Using cached numpy-1.26.3-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken->pyautogen)\n",
      "  Downloading regex-2023.12.25-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB ? eta 0:00:00\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai>=1.3->pyautogen)\n",
      "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai>=1.3->pyautogen)\n",
      "  Using cached certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.3->pyautogen)\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 58.3/58.3 kB ? eta 0:00:00\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.26.0->docker->pyautogen)\n",
      "  Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hchakra1\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai>=1.3->pyautogen) (0.4.6)\n",
      "Downloading pyautogen-0.2.8-py3-none-any.whl (157 kB)\n",
      "   ---------------------------------------- 0.0/157.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 157.8/157.8 kB 9.8 MB/s eta 0:00:00\n",
      "Downloading openai-1.9.0-py3-none-any.whl (223 kB)\n",
      "   ---------------------------------------- 0.0/223.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 223.4/223.4 kB 13.3 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
      "   ---------------------------------------- 0.0/381.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 381.9/381.9 kB 12.0 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.14.6-cp312-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 24.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.7/1.9 MB 21.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 20.0 MB/s eta 0:00:00\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.5/45.5 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading docker-7.0.0-py3-none-any.whl (147 kB)\n",
      "   ---------------------------------------- 0.0/147.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 147.6/147.6 kB ? eta 0:00:00\n",
      "Downloading FLAML-2.1.1-py3-none-any.whl (295 kB)\n",
      "   ---------------------------------------- 0.0/295.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 295.2/295.2 kB 17.8 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tiktoken-0.5.2-cp312-cp312-win_amd64.whl (785 kB)\n",
      "   ---------------------------------------- 0.0/785.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 785.8/785.8 kB 25.0 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading anyio-4.2.0-py3-none-any.whl (85 kB)\n",
      "   ---------------------------------------- 0.0/85.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 85.5/85.5 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.9/75.9 kB ? eta 0:00:00\n",
      "Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.9/76.9 kB ? eta 0:00:00\n",
      "Downloading numpy-1.26.3-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.3/15.5 MB 26.8 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 2.4/15.5 MB 31.1 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.7/15.5 MB 29.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 5.2/15.5 MB 30.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 6.6/15.5 MB 32.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.7/15.5 MB 30.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.0/15.5 MB 30.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.3/15.5 MB 29.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.6/15.5 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.9/15.5 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.4/15.5 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 27.3 MB/s eta 0:00:00\n",
      "Downloading regex-2023.12.25-cp312-cp312-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 268.9/268.9 kB ? eta 0:00:00\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Downloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "   ---------------------------------------- 0.0/104.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 104.6/104.6 kB ? eta 0:00:00\n",
      "Using cached certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
      "Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tqdm, termcolor, sniffio, regex, python-dotenv, NumPy, idna, h11, distro, diskcache, charset-normalizer, certifi, annotated-types, requests, pydantic-core, httpcore, flaml, anyio, tiktoken, pydantic, httpx, docker, openai, pyautogen\n",
      "Successfully installed NumPy-1.26.3 annotated-types-0.6.0 anyio-4.2.0 certifi-2023.11.17 charset-normalizer-3.3.2 diskcache-5.6.3 distro-1.9.0 docker-7.0.0 flaml-2.1.1 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 idna-3.6 openai-1.9.0 pyautogen-0.2.8 pydantic-2.5.3 pydantic-core-2.14.6 python-dotenv-1.0.1 regex-2023.12.25 requests-2.31.0 sniffio-1.3.0 termcolor-2.4.0 tiktoken-0.5.2 tqdm-4.66.1 typing-extensions-4.9.0 urllib3-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pyautogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
